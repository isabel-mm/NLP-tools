import nltk
from nltk.tokenize import sent_tokenize, word_tokenize

import gensim
from gensim.models import Word2Vec

# Word2Vec is an algorithm that transforms words into vectors. I'm using it to get most similar words (i.e. words that mean roughly the same) to any word

text=open("yourtext.txt", "r", encoding="utf8")

t=text.read().lower()

x=t.replace("\n", " ")

data=[]

for word in sent_tokenize(x):
    y=[]
    for a in word_tokenize(word):
        y.append(a.lower())

    data.append(y)

model1 = gensim.models.Word2Vec(data, min_count = 50,
                                vector_size=100, window = 3)

print("Most similar words to 'YOUR WORD GOES HERE' are: ",
      model1.wv.most_similar("YOUR WORD GOES HERE"))
